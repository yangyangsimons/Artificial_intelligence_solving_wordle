{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lynnyang/opt/anaconda3/envs/mle_tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/lynnyang/opt/anaconda3/envs/mle_tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/lynnyang/opt/anaconda3/envs/mle_tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/lynnyang/opt/anaconda3/envs/mle_tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/lynnyang/opt/anaconda3/envs/mle_tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/lynnyang/opt/anaconda3/envs/mle_tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/lynnyang/opt/anaconda3/envs/mle_tf/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/lynnyang/opt/anaconda3/envs/mle_tf/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/lynnyang/opt/anaconda3/envs/mle_tf/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/lynnyang/opt/anaconda3/envs/mle_tf/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/lynnyang/opt/anaconda3/envs/mle_tf/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/lynnyang/opt/anaconda3/envs/mle_tf/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "#Imports libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from PIL import ImageGrab\n",
    "import tkinter as tk\n",
    "import keyboard as kb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the screenshot of the image saved in the directory\n",
    "image = cv2.imread('data/image.png')\n",
    "image = cv2.resize(image, (412, 365))\n",
    "#Convert image to grayscale\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#Sharpen the edges of the image for better contour detection\n",
    "sharpen_kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])\n",
    "sharpen = cv2.filter2D(gray, -1, sharpen_kernel)\n",
    "\n",
    "#Thresholding the image\n",
    "thresh = cv2.threshold(sharpen,225,255, cv2.THRESH_BINARY_INV)[1]\n",
    "\n",
    "#FInd contours in the image\n",
    "cnts = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "#Variable cnts includes all the contours found in the image\n",
    "\n",
    "#The below for loop goes through every contour found and basically crops the image\n",
    "#to every letter in a square and saves it\n",
    "cnts = cnts[::-1] #reverses the list containing contours\n",
    "image_number = 0\n",
    "for c in cnts:\n",
    "    area = cv2.contourArea(c)#finds out area of each contour\n",
    "    print(area)\n",
    "    if area > 800:\n",
    "        x,y,w,h = cv2.boundingRect(c)#produces coordinated (x, y) and height(h) and width(w) of each square-containing alphabet\n",
    "        ROI = image[y:y+h, x:x+w] #crops the image to the square-containing alphabet\n",
    "        ROI = cv2.resize(ROI, (68, 68))#Resizes the square-containing alphabet to 68x68 pixels\n",
    "        cv2.imwrite('Alphabets/ROI_{}.png'.format(image_number), ROI) #saves the square-containing alphabet\n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), (255,0,0), 2) #produces blue-coloured rectangles on each contour found\n",
    "        image_number += 1 #counts number of contours and adds by 1 in the for loop\n",
    "print(image_number)\n",
    "# cv2.imwrite(\"Contours detected in Image\", image) #displays the blue rectangle-bounded image to display all contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0: grey, 1: yellow, 2: green.\n",
    "\n",
    "#Training data consists of different RGB values\n",
    "training_data = np.array([[164, 198, 203], [131, 132, 130], [130, 154, 133], [118, 156, 126], [196, 201, 199], [126, 125, 121], [132, 131, 127], [135, 160, 140], [123, 154, 126], [127, 178, 182], [123, 123, 123], [138, 176, 183], [118, 154, 127], [127, 156, 124], [124, 125, 121], [199, 198, 194], [140, 164, 147], [137, 165, 140], [134, 167, 138], [134, 163, 139], [133, 163, 134], [127, 124, 119], [118, 179, 191], [123, 124, 122], [89, 184, 194], [124, 123, 119], [112, 176, 192], [122, 119, 115], [134, 174, 179], [132, 130, 129], [132, 130, 130], [127, 124, 119], [121, 178, 186], [125, 126, 123], [94, 180, 189], [127, 124, 123], [109, 167, 110], [124, 123, 122], [122, 151, 123], [125, 125, 123], [114, 161, 118], [105, 170, 101], [129, 126, 122], [124, 163, 126], [131, 127, 126], [123, 179, 127], [104, 167, 111], [119, 158, 124], [126, 153, 129], [114, 159, 115], [113, 159, 116]])\n",
    "\n",
    "#Validation data consists of numbers as keys to colors. \n",
    "valid_data = np.array([1, 0, 2, 2, 0, 0, 0, 2, 2, 1, 0, 1, 2, 2, 0, 0, 2, 2, 2, 2, 2, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 2, 0, 2, 0, 2, 2, 0, 2, 0, 2, 2, 2, 2, 2, 2])\n",
    "\n",
    "#Create model\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Dense(3, input_shape=[3], activation='softmax') #3 neurons layer linked to 1 neuron output layer. \n",
    "])\n",
    "model.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['accuracy']) #Optimizer settings\n",
    "\n",
    "#fit the model\n",
    "history = model.fit(\n",
    "        training_data, valid_data, epochs=100\n",
    "        )\n",
    "\n",
    "#save the model\n",
    "model.save('Models/color.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All functions\n",
    "co_model = load_model('Models/color.h5')\n",
    "def crop_center(img,cropx,cropy):\n",
    "    y,x = img.shape\n",
    "    startx = x//2-(cropx//2)\n",
    "    starty = y//2-(cropy//2)    \n",
    "    \n",
    "    return img[starty:starty+cropy,startx:startx+cropx]\n",
    "\n",
    "def predict_color(ROI):\n",
    "    \n",
    "    colors = {0: \"grey\", 1: \"yellow\", 2: \"green\"}\n",
    "    RGB = (np.asarray(ROI)[0][0])\n",
    "    color_pred = co_model.predict(np.array([RGB]))\n",
    "    color_pred = list(list(color_pred.astype(int))[0])\n",
    "    color_index = color_pred.index(max(color_pred))\n",
    "    \n",
    "    return colors[color_index], RGB\n",
    "  \n",
    "def __Website__Feedback__():\n",
    "    #load image\n",
    "    file = 'data/screenshot/img2.png'\n",
    "    image = cv2.imread(file)\n",
    "    image = cv2.resize(image, (412, 365))\n",
    "\n",
    "    #load models\n",
    "    co_model = load_model('Models/color.h5')\n",
    "\n",
    "    #preprocessing of image\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    #blur = cv2.medianBlur(gray, 5)\n",
    "    sharpen_kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])\n",
    "    sharpen = cv2.filter2D(gray, -1, sharpen_kernel)\n",
    "    thresh = cv2.threshold(sharpen,225,255, cv2.THRESH_BINARY_INV)[1]\n",
    "\n",
    "    #find all contours\n",
    "    cnts = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "\n",
    "    image_number = 0\n",
    "    cnts = cnts[::-1]\n",
    "    colours = []\n",
    "    for c in cnts:\n",
    "        area = cv2.contourArea(c)\n",
    "        print(area)\n",
    "        if area > 800:\n",
    "            x,y,w,h = cv2.boundingRect(c)\n",
    "            ROI = image[y:y+h, x:x+w]\n",
    "            ROI = cv2.resize(ROI, (68, 68))\n",
    "            cv2.imwrite('Alphabets/ROI_{}.png'.format(image_number), ROI)\n",
    "\n",
    "            final_color, RGB = predict_color(ROI)\n",
    "            #print alphabet and color predicted and the RGB value associated\n",
    "            print(final_color, RGB) \n",
    "            colours.append(final_color)\n",
    "            cv2.rectangle(image, (x, y), (x + w, y + h), (255,0,0), 2)\n",
    "            image_number += 1\n",
    "    return colours\n",
    "result = __Website__Feedback__()\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "46d134eb557ef08c609e980b92390e3083e10e9de6884d7d452b5ae8f92825d9"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('mle_tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
